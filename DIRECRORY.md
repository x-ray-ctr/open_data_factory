ä»¥ä¸‹ã¯ã€**ä»Šå›ç¢ºå®šã—ãŸåˆ†æã‚µãƒ¼ãƒ“ã‚¹ï¼ˆPolars Ã— uv Ã— K8s Jobï¼‰**ã‚’
**ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£ï¼ˆCAï¼‰ã«å³å¯†æº–æ‹ **ã•ã›ãŸ **æœ€çµ‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆæ¡ˆ**ã§ã™ã€‚

> ãƒã‚¤ãƒ³ãƒˆ
>
> * **ä¾å­˜ã¯å¸¸ã«å†…å‘ã**
> * **Job / API / Notebook ã¯åŒã˜ UseCase ã‚’å©ãã ã‘**
> * **Polars ã¯ Domain / UseCase ã«é–‰ã˜è¾¼ã‚ã‚‹**

---

# ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒ¼ã‚­ãƒ†ã‚¯ãƒãƒ£æœ€çµ‚ãƒ‡ã‚£ãƒ¬ã‚¯ãƒˆãƒªæ§‹æˆ

```
polars-analysis-service/
â”œâ”€â”€ pyproject.toml
â”œâ”€â”€ uv.lock
â”œâ”€â”€ Dockerfile
â”‚
â”œâ”€â”€ src/
â”‚   â””â”€â”€ app/
â”‚
â”‚       â”œâ”€â”€ domain/                # ã‚¨ãƒ³ã‚¿ãƒ¼ãƒ—ãƒ©ã‚¤ã‚ºãƒ«ãƒ¼ãƒ«
â”‚       â”‚   â”œâ”€â”€ model/
â”‚       â”‚   â”‚   â””â”€â”€ analysis_result.py
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ value_object/
â”‚       â”‚   â”‚   â”œâ”€â”€ dataset.py
â”‚       â”‚   â”‚   â””â”€â”€ target_date.py
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ service/
â”‚       â”‚       â””â”€â”€ analyze_service.py
â”‚       â”‚
â”‚       â”œâ”€â”€ usecase/               # ã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³ãƒ«ãƒ¼ãƒ«
â”‚       â”‚   â”œâ”€â”€ ports/
â”‚       â”‚   â”‚   â”œâ”€â”€ input/
â”‚       â”‚   â”‚   â”‚   â””â”€â”€ run_analysis_usecase.py
â”‚       â”‚   â”‚   â””â”€â”€ output/
â”‚       â”‚   â”‚       â”œâ”€â”€ dataset_loader.py
â”‚       â”‚   â”‚       â””â”€â”€ result_repository.py
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ interactor/
â”‚       â”‚   â”‚   â””â”€â”€ run_analysis_interactor.py
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ dto/
â”‚       â”‚       â”œâ”€â”€ run_analysis_input.py
â”‚       â”‚       â””â”€â”€ run_analysis_output.py
â”‚       â”‚
â”‚       â”œâ”€â”€ interface/             # Controller / Presenter
â”‚       â”‚   â”œâ”€â”€ api/
â”‚       â”‚   â”‚   â””â”€â”€ analysis_controller.py
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ job/
â”‚       â”‚   â”‚   â””â”€â”€ analysis_job_controller.py
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ presenter/
â”‚       â”‚       â””â”€â”€ analysis_presenter.py
â”‚       â”‚
â”‚       â”œâ”€â”€ infrastructure/        # å¤–éƒ¨ä¸–ç•Œ
â”‚       â”‚   â”œâ”€â”€ loader/
â”‚       â”‚   â”‚   â””â”€â”€ http_dataset_loader.py
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ repository/
â”‚       â”‚   â”‚   â””â”€â”€ s3_result_repository.py
â”‚       â”‚   â”‚
â”‚       â”‚   â”œâ”€â”€ k8s/
â”‚       â”‚   â”‚   â””â”€â”€ job_launcher.py
â”‚       â”‚   â”‚
â”‚       â”‚   â””â”€â”€ config/
â”‚       â”‚       â””â”€â”€ settings.py
â”‚       â”‚
â”‚       â”œâ”€â”€ main_api.py             # FastAPI entrypoint
â”‚       â”œâ”€â”€ main_job.py             # K8s Job entrypoint
â”‚       â”‚
â”‚       â””â”€â”€ wiring.py               # DIï¼ˆcomposition rootï¼‰
â”‚
â””â”€â”€ notebooks/
    â””â”€â”€ integration.ipynb           # ä»®è¨­ãƒ»æœ€çµ‚å‰Šé™¤
```

---

# ãƒ¬ã‚¤ãƒ¤åˆ¥ã®å½¹å‰²ï¼ˆå³å¯†ï¼‰

## 1. domainï¼ˆæœ€å†…å±¤ï¼‰

**è²¬å‹™**

* åˆ†æã®æœ¬è³ª
* ãƒ“ã‚¸ãƒã‚¹ãƒ«ãƒ¼ãƒ«
* Polars ã‚’ä½¿ã£ãŸ *ç´”ç²‹å¤‰æ›*

```python
# domain/service/analyze_service.py
import polars as pl

def analyze(df: pl.DataFrame) -> pl.DataFrame:
    return (
        df.group_by("category")
          .agg(pl.sum("value").alias("total"))
    )
```

â— I/Oãƒ»ç’°å¢ƒå¤‰æ•°ãƒ»S3 ã‚’ä¸€åˆ‡çŸ¥ã‚‰ãªã„

---

## 2. usecaseï¼ˆã‚¢ãƒ—ãƒªã‚±ãƒ¼ã‚·ãƒ§ãƒ³å±¤ï¼‰

**è²¬å‹™**

* å‡¦ç†ã®æµã‚Œã‚’å®šç¾©
* Port ã‚’é€šã—ã¦å¤–ç•Œã¨é€šä¿¡

```python
# usecase/interactor/run_analysis_interactor.py
class RunAnalysisInteractor:
    def __init__(self, loader, repository, analyzer):
        self.loader = loader
        self.repository = repository
        self.analyzer = analyzer

    def run(self, input):
        df = self.loader.load(input.dataset)
        result = self.analyzer(df)
        self.repository.save(result, input.target_date)
```

---

## 3. interfaceï¼ˆå…¥å£ï¼‰

### API Controller

```python
# interface/api/analysis_controller.py
def post_analysis(request):
    return usecase.run(request)
```

### Job Controller

```python
# interface/job/analysis_job_controller.py
def run_from_env():
    input = build_input_from_env()
    usecase.run(input)
```

ğŸ‘‰ **API / Job ã¯åŒã˜ UseCase ã‚’å‘¼ã¶**

---

## 4. infrastructureï¼ˆå¤–ç•Œï¼‰

* HTTP / S3 / K8s / Env
* å·®ã—æ›¿ãˆå‰æ
* ãƒ†ã‚¹ãƒˆã§ã¯ãƒ¢ãƒƒã‚¯

```python
# infrastructure/repository/s3_result_repository.py
def save(df, date):
    df.write_parquet(f"s3://analysis/{date}/result.parquet")
```

---

## 5. wiringï¼ˆComposition Rootï¼‰

```python
# wiring.py
def build_usecase():
    loader = HttpDatasetLoader()
    repo = S3ResultRepository()
    analyzer = analyze
    return RunAnalysisInteractor(loader, repo, analyzer)
```

**ä¾å­˜æ³¨å…¥ã¯ã“ã“ã ã‘**

---

# Notebook ã®ä½ç½®ä»˜ã‘ï¼ˆCAçš„ã«æ­£ã—ã„ï¼‰

```
Notebook
  â†“
Interfaceï¼ˆä»®Controllerï¼‰
  â†“
UseCase
  â†“
Domain
```

Notebook ã¯ **Interface ã®ä»£æ›¿**
ï¼ æ¶ˆã›ã‚‹ã®ãŒæ­£ã—ã„ã€‚

---

# ã“ã®æ§‹æˆã®å¼·ã•

* Job / API / Notebook å®Œå…¨å…±å­˜
* Domain ãŒæœ€å¼·ã«ãƒ†ã‚¹ãƒˆã—ã‚„ã™ã„
* Polars ä¾å­˜ãŒå¤–ã«æ¼ã‚Œãªã„
* 10å¹´ä¿ã¤æ§‹é€ 

---

## æœ€çµ‚ç¢ºèªï¼ˆYES ãªã‚‰è¨­è¨ˆå®Œæˆï¼‰

* [ ] Notebook ã‚’å‰Šé™¤ã—ã¦ã‚‚å‹•ã
* [ ] Domain ã¯ Polars ä»¥å¤–ã‚’çŸ¥ã‚‰ãªã„
* [ ] Job ã¨ API ãŒåŒã˜ UseCase ã‚’å‘¼ã¶
* [ ] S3 / HTTP ã‚’å·®ã—æ›¿ãˆã‚‰ã‚Œã‚‹

---

æ¬¡ã®è‡ªç„¶ãªã‚¹ãƒ†ãƒƒãƒ—ã¯
**â‘  ã“ã®æ§‹æˆã§ã®æœ€å°å®Ÿè£…ã‚³ãƒ¼ãƒ‰ä¸€å¼**
**â‘¡ Terraform + K8s ã¸ã®å®Œå…¨å±•é–‹**

ã©ã¡ã‚‰ã«é€²ã‚ã¾ã™ã‹ã€‚
